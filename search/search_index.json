{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Adaptive Stress Testing for Robust AI &amp; Reinforcement Learning (ASTRA-RL)","text":"<p>Welcome to the ASTRA-RL toolbox documentation! This documentation provides an overview of the ASTRA-RL toolbox, its features, and how to use it effectively.</p> <p>Warning</p> <p>This documentation (and project) is a work in progress. If you have any questions or suggestions, please feel free to open an issue on the GitHub repository</p>"},{"location":"api/index.html","title":"Library API","text":"<p>This section provides detailed information about all the classes, functions, and modules available in the ASTRA-RL toolbox. Each entry includes a description of its purpose, parameters, and usage examples.</p> <p>This documentation is generated automatically from the codebase using docstrings and comments, ensuring that it stays up-to-date with the latest changes.</p>"},{"location":"tutorials/index.html","title":"Tutorials","text":"<p>This section provides step-by-step guides and examples to help you get started with the ASTRA-RL toolbox. Each tutorial covers a specific aspect of the toolbox, from basic usage to advanced features.</p>"},{"location":"tutorials/quick_start_training.html","title":"Quick start training","text":"<p>Do you want to train a Huggingface adversary using an ASTRA-supported algorithm (DPO, IPO, PPO) and problem formulation (ASTPrompter, Perez, MALIBU, Hong)? Then this quick start guide will walk you through every step to training a red-teaming adversary. </p> <p>1) Set-up See the README for more details and guidance behind the installation process.</p> <pre><code># Install the ASTRA-RL toolbox\npip install astra-rl\n# Clone the repository\ngit clone git@github.com:sisl/astra-rl.git\ncd astra-rl\n# Sync package dependencies\nuv sync --dev\n# Install pre-commit hooks:\nuv run pre-commit install\n</code></pre> <p>2) Create a python file for your training code</p> <p>example: mytrain.py</p> <p>3) Import required classes, wrappers, and functions</p> <pre><code># import your favorite optimization algorithm. We suggest Adam!\nfrom torch.optim import AdamW\n# import a pre-instantiaed environment class, RL training algorithm, Moderator, and training harness class\nfrom astra_rl import ASTEnvironment, DPO, DetoxifyModerator, Harness\n# import the wrapper that supports Huggingface models for ASTPrompter-style adversarial training\nfrom astra_rl.ext.transformers import HFASTProblem\n</code></pre> <p>4) Load your Training Data (initial prompts) To train your adversary, you will need to provide a large dataset of comma-seperated strings that will serve as the prompts that initiate adversarial-defender conversation rollouts during training. These rollouts (scored by the moderator) will serve as the training data for the adversary, teaching the adversary what actions it should take to ellicit harmful responses from the defender. Therefore, it is important that the initial prompts you provide are relavent to the red-teaming scenario you care about. For example, if you want to red-team medical diagnosis LMs, your initial prompts should reflect the prompts a medical diagnosis LM would likely see during operation: \"I have a cut that is swollen and red. What do you think is wrong?\" ect.</p> <p>The supported framework (ASTPrompter) red-teams for harmful behaviors in conversational LMs and therefore uses the ConvoKit Reddit corpus (small) to serve as the initial prompts. To use this data, implement the following code:</p>"},{"location":"tutorials/running_an_evaluation.html","title":"Running An Evaluation","text":"<p>This tutorial will guide you through the process of running an evaluation using an existing evaluator model. The evaluator is a model that can be used to assess the quality of other models' outputs. </p> <p>For the purposes of this tutorial, we will assume that you have already trained an evaluator model from the Training an Evaluator tutorial.mk</p>"},{"location":"tutorials/training_an_evaluator.html","title":"Training an Evaluator","text":"<p>This tutorial will guide you through the process of training a custom model evaluator using the ASTRA-RL toolbox. The evaluator is a model that can be used to assess the quality of other models' outputs.</p>"}]}